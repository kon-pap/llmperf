import json
import os

from dataclasses import dataclass, field
from typing import Callable, Dict, List, LiteralString, Optional, Union

from llmperf.constants import DATASETS_DIR
from llmperf.preprocessing.input import (
    get_clotho_input,
    get_llava_image_reasoning_input,
    get_llava_video_description_input,
    get_sharegpt_input,
    get_sharegpt_long_input,
    get_mmbench_mc_input,
    get_llavabench_qna_input,
    get_cocoval_captioning_input,
    get_videomme_mc_input,
    get_mmbench_video_qna_input,
    get_tempcompass_captioning_input,
)

from llmperf.preprocessing.output import (
    get_clotho_output,
    get_llava_image_reasoning_output,
    get_llava_video_description_output,
    get_sharegpt_output,
    get_sharegpt_long_output,
    get_mmbench_mc_output,
)

from llmperf.preprocessing.modality_info import (
    get_audio_path,
    get_audio_size,
    get_image_path,
    get_image_size,
    get_video_path,
    get_video_size,
)
@dataclass
class Dataset:
    name: str
    path: Union[str,LiteralString]
    file: str
    alias: str
    color: Optional[str] = None

    get_input: Callable[[Optional[Dict]], Optional[str]] = field(default=None)
    get_output: Callable[[Dict], Optional[str]] = field(default=None)
    _get_modality_path: Callable[[Union[str,LiteralString],Dict], Union[str,LiteralString]] = field(default=None)
    _get_modality_size: Callable[[Union[str,LiteralString],Dict], Dict] = field(default=None)

    def get_modality_path(self, record: Dict) -> Union[str,LiteralString]:
        return self._get_modality_path(self.path, record)

    def get_modality_size(self, record: Dict) -> Dict:
        return self._get_modality_size(self.path, record)

    def __hash__(self):
        return hash((self.name, self.alias))
    
    def __eq__(self, other):
        if isinstance(other, Dataset):
            return self.name == other.name and self.alias == other.alias
        return False

    def load(self) -> List[dict]:
        with open(os.path.join(self.path, self.file)) as f:
            data = []
            for line in f:
                data.append(json.loads(line))
            return data

DATASETS = {
    Dataset(
        name="Text Conversations",
        path=os.path.join(DATASETS_DIR, "ShareGPT"),
        file="sharegpt.jsonl",
        alias="text-conv",
        color="#577FBC",
        get_input=get_sharegpt_input,
        get_output=get_sharegpt_output
    ),
    Dataset(
        name="Image Reasoning",
        path=os.path.join(DATASETS_DIR, "LLaVA-Instruct-150K"),
        file="complex_reasoning.jsonl",
        alias="img-reason",
        color="#57B593",
        get_input=get_llava_image_reasoning_input,
        get_output=get_llava_image_reasoning_output,
        _get_modality_path=get_image_path,
        _get_modality_size=get_image_size
    ),
    Dataset(
        name="Video Description",
        path=os.path.join(DATASETS_DIR, "LLaVA-Video"),
        file="description.jsonl",
        alias="vid-desc",
        color="#F8DE4B",
        get_input=get_llava_video_description_input,
        get_output=get_llava_video_description_output,
        _get_modality_path=get_video_path,
        _get_modality_size=get_video_size
    ),
    Dataset(
        name="Audio Captioning",
        path=os.path.join(DATASETS_DIR, "Clotho"),
        file="captioning.jsonl",
        alias="audio-cap",
        color="#E16F65",
        get_input=get_clotho_input,
        get_output=get_clotho_output,
        _get_modality_path=get_audio_path,
        _get_modality_size=get_audio_size
    ),
    Dataset(
        name="Long Text Conversations",
        path=os.path.join(DATASETS_DIR, "ShareGPT"),
        file="sharegpt.jsonl",
        alias="text-conv-long",
        color="#000000",
        get_input=get_sharegpt_long_input,
        get_output=get_sharegpt_long_output
    ),
    Dataset(
        name="Multiple Choice (MMBench)",
        path=os.path.join(DATASETS_DIR, "MMBench"),
        file="multiple_choice.jsonl",
        alias="mmbench-mc",
        color="#57B593",
        get_input=get_mmbench_mc_input,
        get_output=get_mmbench_mc_output,
        _get_modality_path=get_image_path,
        _get_modality_size=get_image_size
    ),
    Dataset(
        name="Q&A (LLaVABench)",
        path=os.path.join(DATASETS_DIR, "LLaVABench"),
        file="qna.jsonl",
        alias="llavabench-qna",
        color="#57B593",
        get_input=get_llavabench_qna_input,
        get_output=get_clotho_output,
        _get_modality_path=get_image_path,
        _get_modality_size=get_image_size
    ),
    Dataset(
        name="Captioning (COCO-Val)",
        path=os.path.join(DATASETS_DIR, "COCO-Val"),
        file="captioning.jsonl",
        alias="cocoval-captioning",
        color="#57B593",
        get_input=get_cocoval_captioning_input,
        get_output=get_mmbench_mc_output,
        _get_modality_path=get_image_path,
        _get_modality_size=get_image_size
    ),
    Dataset(
        name="Multiple Choice (Video-MME)",
        path=os.path.join(DATASETS_DIR, "Video-MME"),
        file="multiple_choice.jsonl",
        alias="videomme-mc",
        color="#F8DE4B",
        get_input=get_videomme_mc_input,
        get_output=get_mmbench_mc_output,
        _get_modality_path=get_video_path,
        _get_modality_size=get_video_size
    ),
    Dataset(
        name="Q&A (MMBench-Video)",
        path=os.path.join(DATASETS_DIR, "MMBench-Video"),
        file="qna.jsonl",
        alias="mmbench-video-qna",
        color="#F8DE4B",
        get_input=get_mmbench_video_qna_input,
        get_output=get_mmbench_mc_output,
        _get_modality_path=get_video_path,
        _get_modality_size=get_video_size
    ),
    Dataset(
        name="Captioning (TempCompass)",
        path=os.path.join(DATASETS_DIR, "TempCompass"),
        file="captioning.jsonl",
        alias="tempcompass-captioning",
        color="#F8DE4B",
        get_input=get_tempcompass_captioning_input,
        get_output=get_mmbench_mc_output,
        _get_modality_path=get_video_path,
        _get_modality_size=get_video_size
    )
}

def get_dataset_by_name(name: str) -> Union[None, Dataset]:
    for dataset in DATASETS:
        if getattr(dataset, "name", None) == name:
            return dataset
    return None

def get_dataset_by_alias(alias: str) -> Union[None, Dataset]:
    for dataset in DATASETS:
        if getattr(dataset, "alias", None) == alias:
            return dataset
    return None